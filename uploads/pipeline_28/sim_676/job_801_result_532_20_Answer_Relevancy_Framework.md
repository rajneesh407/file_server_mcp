
    LLM-as-a-Judge will produce a **score of 1 to 5** based on whether the response addresses the user message in an expected way.  
    By perturbing the same user messages in different *minor* ways, we are testing the stability of the **answer relevancy score** (Total Agreement Rate and % Stable).  

    ##### ðŸ“Š Scoring Scale  

    **Score 1** â†’ Poor Relevancy  
    **Score 2** â†’ Below Average  
    **Score 3** â†’ Average  
    **Score 4** â†’ Good Relevancy  
    **Score 5** â†’ Excellent  
    