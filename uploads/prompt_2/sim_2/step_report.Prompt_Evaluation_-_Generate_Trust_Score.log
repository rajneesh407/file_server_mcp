[2025-06-20 08:52:43 UTC] Report execution completed. Generating outputs...
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] Error occured while generating Report Output "Overall Trust Score"
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] ---------------------------------------------------------------------------
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] IndexError                                Traceback (most recent call last):
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]  Report Output "Overall Trust Score" <v1>, line 70, in <definition>
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]         65 |     for i in fig["layout"]["annotations"]:
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]         66 |         i["font"] = dict(size=20, color="#424242")
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]         67 |     return fig
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] ---->   70 | return gauge_charts(raw_output)
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]                     ^^^^^^^^^^^^^^^^^^^^^^^^
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]     Local variables:
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       job           = <Job job_type="Simulati...: Jun-20-2025 02:21 PM">
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       raw_output    = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]  Report Output "Overall Trust Score" <v1>, line 22, in gauge_charts
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]         19 | row_idx = 1
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]         20 | col_idx = 1
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]         21 | for model_name, data in raw_output.items():
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] ---->   22 |     overall_readiness = data["overall_readiness"]
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]                                      ^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]         23 |     if overall_readiness >= 85:
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]     Local variables:
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       raw_output    = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       num_models    = 4
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       rows          = 2
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       fig           = Figure({
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]                           'data': []...   'template': '...'}
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]                       })
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       row_idx       = 1
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       col_idx       = 1
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       model_name    = 'overall_readiness'
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC]       data          = 66.67
[2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] [2025-06-20 08:52:43 UTC] IndexError: invalid index to scalar variable.
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] Error occured while generating Report Output "Radial Chart"
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---------------------------------------------------------------------------
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] IndexError                                Traceback (most recent call last):
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]  Report Output "Radial Chart" <v1>, line 28, in <definition>
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         10 |         fig.add_trace(
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         11 |             go.Scatterpolar(
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         12 |                 r=df["Mean Score"].tolist() + [df["Mean Score"].tolist()[0]],
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] (...)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         16 |             )
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         17 |         )
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         19 |     fig.update_layout(
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         20 |         title="<b>Evaluation Scores Across Multiple Risk Dimensions</b><br>(1: Worst Case, 5: Best Case)",
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         21 |         polar=dict(radialaxis=dict(visible=True, range=[0, 5])),
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         22 |         showlegend=len(raw_output) > 1,
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         23 |         title_x=0.5,
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         24 |     )
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         25 |     return fig
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---->   28 | return radial_chart(raw_output)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                     ^^^^^^^^^^^^^^^^^^^^^^^^
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]     Local variables:
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       job           = <Job job_type="Simulati...: Jun-20-2025 02:21 PM">
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       raw_output    = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]  Report Output "Radial Chart" <v1>, line 8, in radial_chart
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          4 | def radial_chart(output_dict):
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          5 |     fig = go.Figure()
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          7 |     for prompt_name, prompt_data in output_dict.items():
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---->    8 |         df = prompt_data["metrics_df"].copy(deep=True)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                           ^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          9 |         df = df[0 : len(df) - 1]
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]     Local variables:
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       output_dict   = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       fig           = Figure({
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                           'data': []...: {'template': '...'}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                       })
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       prompt_name   = 'overall_readiness'
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       prompt_data   = 66.67
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] IndexError: invalid index to scalar variable.
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] Error occured while generating Report Output "Quality Tags"
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---------------------------------------------------------------------------
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] TypeError                                 Traceback (most recent call last):
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]  Report Output "Quality Tags" <v1>, line 147, in <definition>
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        123 |     initial_chart_title = f"{chart_base_title}<br><br>{initial_issues_summary}"
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        125 |     fig.update_layout(
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        126 |         xaxis_title="<b>Assessment Categories</b>",
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        127 |         yaxis_title="",
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] (...)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        141 |         paper_bgcolor="rgba(0,0,0,0)",
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        142 |     )
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        144 |     return fig
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---->  147 | return generate_tags_comparison_chart(raw_output)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]     Local variables:
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       job           = <Job job_type="Simulati...: Jun-20-2025 02:21 PM">
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       raw_output    = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]  Report Output "Quality Tags" <v1>, line 10, in generate_tags_comparison_chart
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          7 |     raise ValueError("Input data_dict cannot be empty.")
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          8 | all_data_frames = []
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          9 | for prompt_name, df in data_dict.items():
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---->   10 |     df_chart = df.copy(deep=True)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                             ^^^^^^^^^^^^^^^^^^
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         11 |     df_chart["Prompt"] = prompt_name
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]     Local variables:
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       data_dict     = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       title         = None
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       all_data_frames = []
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       prompt_name   = 'overall_readiness'
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       df            = 66.67
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] TypeError: copy() got an unexpected keyword argument 'deep'
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] Error occured while generating Report Output "Metrics Table"
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---------------------------------------------------------------------------
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] IndexError                                Traceback (most recent call last):
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]  Report Output "Metrics Table" <v1>, line 115, in <definition>
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        103 |         html += "</tr>"
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        105 |     html += """
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        106 |                     </tbody>
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        107 |                 </table>
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] (...)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        110 |     </div>
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        111 |     """
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        112 |     return html
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---->  115 | consolidated_df = consolidated_metrics_table(raw_output)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]        116 | return generate_metrics_html(consolidated_df)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]     Local variables:
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       job           = <Job job_type="Simulati...: Jun-20-2025 02:21 PM">
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       raw_output    = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]  Report Output "Metrics Table" <v1>, line 10, in consolidated_metrics_table
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          7 | prompt_names = list(raw_output.keys())
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          8 | if not prompt_names:
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]          9 |     return pd.DataFrame()
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---->   10 | first_prompt_metrics_df = raw_output[prompt_names[0]]["metrics_df"]
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         11 | if isinstance(first_prompt_metrics_df, list):
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]     Local variables:
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       raw_output    = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       consolidated_rows = []
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       prompt_names  = ['overall_readiness', 'metrics_df', 'tags_df', 'pointers_for_improvement']
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] IndexError: invalid index to scalar variable.
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] Error occured while generating Report Output "Overall Evaluation Pointers"
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---------------------------------------------------------------------------
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] AttributeError                            Traceback (most recent call last):
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]  Report Output "Overall Evaluation Pointers" <v1>, line 69, in <definition>
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         47 |         html_output += "<hr style='border-top: 2px solid #bdc3c7; margin: 25px 0;'>"
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         49 |     html_output += """
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         50 |     <script>
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         51 |         var coll = document.getElementsByClassName("collapsible");
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] (...)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         64 |     </script>
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         65 |     """
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         66 |     return html_output
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---->   69 | return generate_pointers_html(raw_output)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]     Local variables:
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       job           = <Job job_type="Simulati...: Jun-20-2025 02:21 PM">
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       raw_output    = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]  Report Output "Overall Evaluation Pointers" <v1>, line 35, in generate_pointers_html
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         31 | for prompt_name, data in output_data.items():
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         32 |     if prompt_name == "current_prompt":
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         33 |         continue  # Skip current_prompt as it's handled above
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] ---->   35 |     challenger_readiness = data.get("overall_readiness", 0)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]                                         ^^^^^^^^
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]         36 |     challenger_button_color = get_readiness_color(challenger_readiness)
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]     Local variables:
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       output_data   = {'metrics_df': pandas.DataFrame[Metric: object, Score Reviewer-1: float64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, Mean Score: float64, common_tags: object], 'overall_readiness': 66.67, 'pointers_for_improvement': 'Based on a thorough an...iased in all scenarios.', 'tags_df': pandas.DataFrame[Metric: object, Category: object, is_fine: int64]}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       html_output   = '\n        <h2 style="c...3c7; margin: 25px 0;\'>'
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       current_prompt_data = {}
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       prompt_name   = 'overall_readiness'
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC]       data          = 66.67
[2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] [2025-06-20 08:52:44 UTC] AttributeError: 'numpy.float64' object has no attribute 'get'
[2025-06-20 08:52:44 UTC] All 5 outputs processed.
