---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last):
 Report "Prompt Quality Evaluation" <v1>, line 108, in <definition>
       103 |     return overall_readiness, metrics_df, tags_df
       106 | test_prompt = data["current"].toPandas()["output"].iloc[0]
       107 | test_goal = job.current.description
---->  108 | overall_readiness, metrics_df, tags_df = evaluate(test_prompt, test_goal)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
       109 | return {"overall_readiness": overall_readiness, "metrics_df": metrics_df, "tags_df": tags_df}
    Local variables:
      job           = <Job job_type="Simulati...: Sep-04-2025 08:31 PM">
      data          = {'current': <spark df>}
      test_prompt   = '# PERSONA & TONE\nYou ...story: []\n            '
      test_goal     = 'This is a comprehensiv...ion and audit purposes.'
 Report "Prompt Quality Evaluation" <v1>, line 103, in evaluate
       100 |     metrics_df["common_tags"] = metrics_df["common_tags"].apply(lambda x: sorted(list(x)))
       101 |     flattened_tags = [tag for sublist in metrics_df["common_tags"] for tag in sublist]
       102 |     tags_df["is_fine"] = tags_df["Category"].apply(lambda tag: 1 if tag in flattened_tags else 0)
---->  103 | return overall_readiness, metrics_df, tags_df
                    ^^^^^^^^^^^^^^^^^
    Local variables:
      prompt        = '# PERSONA & TONE\nYou ...story: []\n            '
      goal          = 'This is a comprehensiv...ion and audit purposes.'
      metric_scores_and_reasoning = {'Bias Safety Score': {'Reviewer-1': {'explanation': [], 'response': 'The prompt is well-str...sk of biased responses.', 'score': 5, 'tags': []}}, 'Clarity': {'Reviewer-1': {'explanation': [{'comment': 'The prompt has a secti... logical inconsistency.', 'suggestion': 'Rephrase the condition...t a plausible scenario.', 'tags': ['Logical Flow', 'Consistency of Ideas']}, {'comment': "In the 'Card Activatio...io seems contradictory.", 'suggestion': "Clarify this scenario....hey mean by 'activate'.", 'tags': ['Logical Flow', 'Consistency of Ideas', 'Sentence Clarity']}, {'comment': "In the 'Card Activatio...rds are already active.", 'suggestion': 'Adjust the example res...r meant something else.', 'tags': ['Logical Flow', 'Consistency of Ideas']}, {'comment': "In the 'GENERAL GUIDEL...n't provide confidence.", 'suggestion': 'Provide more specific ...shed from chat history.', 'tags': ['Sentence Clarity']}, {'comment': "In the 'HANDLING OUT-O...esponses more smoothly.", 'suggestion': "Consider providing exa...k 'append' if possible.", 'tags': ['Sentence Clarity', 'Logical Flow']}, {'comment': "In 'TASK-SPECIFIC GUID...io seems contradictory.", 'suggestion': "Clarify this scenario....hey mean by 'activate'.", 'tags': ['Logical Flow', 'Consistency of Ideas', 'Sentence Clarity']}, ...], 'response': 'The prompt is mostly c...l ambiguity for the AI.', 'score': 3, 'tags': ['Logical Flow', 'Consistency of Ideas', 'Sentence Clarity']}}, 'Grammatical Correctness': {'Reviewer-1': {'explanation': [{'comment': "In the 'Maintain a ton...arallelism of the list.", 'suggestion': "Consider rephrasing fo...anguage: English only.'", 'tags': ['Consistency and Parallelism']}, {'comment': "In the 'GENERAL GUIDEL...d could be more direct.", 'suggestion': "Consider rephrasing to...provide when relevant.'", 'tags': ['Grammar Usage', 'Sentence Structure Issues']}, {'comment': "In the 'HANDLING OUT-O...d be improved for flow.", 'suggestion': "Consider rephrasing to... handle it separately.'", 'tags': ['Preposition/Article Use']}, {'comment': "In 'TASK-SPECIFIC GUID...or and a missing comma.", 'suggestion': "It should be 'If all t...like card number, etc.'", 'tags': ['Spelling Issues', 'Punctuation Errors', 'Preposition/Article Use']}, {'comment': "In 'TASK-SPECIFIC GUID...issing a question mark.", 'suggestion': "It should be 'I can as...ould like to activate?'", 'tags': ['Punctuation Errors']}, {'comment': "In 'TASK-SPECIFIC GUID...for better readability.", 'suggestion': "It should be 'If the u...eed information about.'", 'tags': ['Punctuation Errors']}, ...], 'response': 'The prompt is generall...y hinder comprehension.', 'score': 4, 'tags': ['Consistency and Parallelism', 'Grammar Usage', 'Sentence Structure Issues', 'Preposition/Article Use', 'Spelling Issues', 'Punctuation Errors']}}, 'Logical Progression and Coherence': {'Reviewer-1': {'explanation': [{'comment': "In the 'Card Activatio... they want to activate.", 'suggestion': 'Revise this sub-bullet...ovide more details."\'.', 'tags': ['Inconsistent Argumentation', 'Disjointed Ideas']}, {'comment': "In the 'Customer Credi...ould enhance coherence.", 'suggestion': "Add a line to confirm ...ual fee, usage limit).'", 'tags': ['Weak Transitions']}], 'response': 'The prompt generally d...nt logical progression.', 'score': '4', 'tags': ['Inconsistent Argumentation', 'Disjointed Ideas', 'Weak Transitions']}}, ...}
      metric        = 'Bias Safety Score'
      current_metric = 'You are an expert eval... any)"]\n}}<END FORMAT>'
      model         = 'Reviewer-1'
      response      = {'human reason': 'The prompt is well-str...sk of biased responses.', 'reason': [], 'score': 5, 'tags': []}
      rows          = [{'Explanation Reviewer-1': [{'comment': "In the 'Maintain a ton...arallelism of the list.", 'suggestion': "Consider rephrasing fo...anguage: English only.'", 'tags': ['Consistency and Parallelism']}, {'comment': "In the 'GENERAL GUIDEL...d could be more direct.", 'suggestion': "Consider rephrasing to...provide when relevant.'", 'tags': ['Grammar Usage', 'Sentence Structure Issues']}, {'comment': "In the 'HANDLING OUT-O...d be improved for flow.", 'suggestion': "Consider rephrasing to... handle it separately.'", 'tags': ['Preposition/Article Use']}, {'comment': "In 'TASK-SPECIFIC GUID...or and a missing comma.", 'suggestion': "It should be 'If all t...like card number, etc.'", 'tags': ['Spelling Issues', 'Punctuation Errors', 'Preposition/Article Use']}, {'comment': "In 'TASK-SPECIFIC GUID...issing a question mark.", 'suggestion': "It should be 'I can as...ould like to activate?'", 'tags': ['Punctuation Errors']}, {'comment': "In 'TASK-SPECIFIC GUID...for better readability.", 'suggestion': "It should be 'If the u...eed information about.'", 'tags': ['Punctuation Errors']}, ...], 'Metric': 'Grammatical Correctness', 'Response Reviewer-1': 'The prompt is generall...y hinder comprehension.', 'Score Reviewer-1': 4, ...}, {'Explanation Reviewer-1': [{'comment': 'The prompt has a secti... logical inconsistency.', 'suggestion': 'Rephrase the condition...t a plausible scenario.', 'tags': ['Logical Flow', 'Consistency of Ideas']}, {'comment': "In the 'Card Activatio...io seems contradictory.", 'suggestion': "Clarify this scenario....hey mean by 'activate'.", 'tags': ['Logical Flow', 'Consistency of Ideas', 'Sentence Clarity']}, {'comment': "In the 'Card Activatio...rds are already active.", 'suggestion': 'Adjust the example res...r meant something else.', 'tags': ['Logical Flow', 'Consistency of Ideas']}, {'comment': "In the 'GENERAL GUIDEL...n't provide confidence.", 'suggestion': 'Provide more specific ...shed from chat history.', 'tags': ['Sentence Clarity']}, {'comment': "In the 'HANDLING OUT-O...esponses more smoothly.", 'suggestion': "Consider providing exa...k 'append' if possible.", 'tags': ['Sentence Clarity', 'Logical Flow']}, {'comment': "In 'TASK-SPECIFIC GUID...io seems contradictory.", 'suggestion': "Clarify this scenario....hey mean by 'activate'.", 'tags': ['Logical Flow', 'Consistency of Ideas', 'Sentence Clarity']}, ...], 'Metric': 'Clarity', 'Response Reviewer-1': 'The prompt is mostly c...l ambiguity for the AI.', 'Score Reviewer-1': 3, ...}, {'Explanation Reviewer-1': [{'comment': "In the 'Card Activatio... they want to activate.", 'suggestion': 'Revise this sub-bullet...ovide more details."\'.', 'tags': ['Inconsistent Argumentation', 'Disjointed Ideas']}, {'comment': "In the 'Customer Credi...ould enhance coherence.", 'suggestion': "Add a line to confirm ...ual fee, usage limit).'", 'tags': ['Weak Transitions']}], 'Metric': 'Logical Progression and Coherence', 'Response Reviewer-1': 'The prompt generally d...nt logical progression.', 'Score Reviewer-1': 4, ...}, {'Explanation Reviewer-1': [{'comment': 'The examples provided ...r international usage).', 'suggestion': 'Add examples that demo...to update card details.', 'tags': ['Limited Diversity', 'Sufficiency of Examples']}, {'comment': 'Example 1 correctly de...follows the guidelines.', 'suggestion': 'No specific fix needed...s are required overall.', 'tags': []}, {'comment': 'Example 2 is relevant ...he tagging is accurate.', 'suggestion': 'No specific fix needed...s are required overall.', 'tags': []}, {'comment': 'The prompt includes de...service request review.', 'suggestion': 'Add at least one examp...comprehensive coverage.', 'tags': ['Limited Diversity', 'Sufficiency of Examples']}, {'comment': "There are no examples ... prompt's instructions.", 'suggestion': 'Include examples that ...re SQL returns no data.', 'tags': ['Limited Diversity', 'Sufficiency of Examples']}], 'Metric': 'Quality of Examples', 'Response Reviewer-1': 'The provided examples ...guideline applications.', 'Score Reviewer-1': 3, ...}, {'Explanation Reviewer-1': [{'comment': 'The prompt explicitly ...enting toxic responses.', 'suggestion': 'No changes needed as t... against toxic content.', 'tags': []}], 'Metric': 'Toxicity Safety Score', 'Response Reviewer-1': 'The prompt is designed...ul input appropriately.', 'Score Reviewer-1': 5, ...}, {'Explanation Reviewer-1': [], 'Metric': 'Bias Safety Score', 'Response Reviewer-1': 'The prompt is well-str...sk of biased responses.', 'Score Reviewer-1': 5, ...}]
      models        = {'Reviewer-1': {'explanation': [], 'response': 'The prompt is well-str...sk of biased responses.', 'score': 5, 'tags': []}}
      row           = {'Explanation Reviewer-1': [], 'Metric': 'Bias Safety Score', 'Response Reviewer-1': 'The prompt is well-str...sk of biased responses.', 'Score Reviewer-1': 5, ...}
      model_name    = 'Reviewer-1'
      details       = {'explanation': [], 'response': 'The prompt is well-str...sk of biased responses.', 'score': 5, 'tags': []}
      metrics_df    = pandas.DataFrame[Metric: object, Score Reviewer-1: int64, Explanation Reviewer-1: object, Response Reviewer-1: object, Tags Reviewer-1: object, common_tags: object]
      tags_df       = pandas.DataFrame[Metric: object, Category: object, is_fine: int64]
NameError: cannot access free variable 'overall_readiness' where it is not associated with a value in enclosing scope
Logs:
[2025-09-04 15:03:43 UTC] Error occured while running Report "Prompt Quality Evaluation" definition